{
 "cells": [
  {
   "cell_type": "code",
   "id": "6eb98a88db25f905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T16:59:26.250741Z",
     "start_time": "2025-12-10T16:59:26.246695Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import HGTConv\n",
    "\n",
    "SPEECH_EMB_DIM = 768\n",
    "\n",
    "\n",
    "class SpeechHeteroGNN(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_heads=2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # --- MLP for speech embeddings ---\n",
    "        self.speech_mlp = nn.Sequential(\n",
    "            nn.Linear(SPEECH_EMB_DIM, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # --- Linear projections for other node types ---\n",
    "        self.node_lin = nn.ModuleDict({\n",
    "            \"author\": nn.Linear(1, hidden_dim),\n",
    "            \"topic\": nn.Linear(1, hidden_dim),\n",
    "            \"day\": nn.Linear(1, hidden_dim),\n",
    "        })\n",
    "\n",
    "        # --- HGTConv ---\n",
    "        self.hgt = HGTConv(\n",
    "            in_channels=hidden_dim,\n",
    "            out_channels=hidden_dim,\n",
    "            metadata=(\n",
    "                [\"author\", \"speech\", \"topic\", \"day\"],\n",
    "                [\n",
    "                    (\"author\", \"gives\", \"speech\"),\n",
    "                    (\"speech\", \"rev_gives\", \"author\"),\n",
    "                    (\"speech\", \"mentions\", \"topic\"),\n",
    "                    (\"topic\", \"rev_mentions\", \"speech\"),\n",
    "                    (\"day\", \"references\", \"speech\"),\n",
    "                    (\"speech\", \"rev_references\", \"day\"),\n",
    "                ]\n",
    "            ),\n",
    "            heads=num_heads\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "\n",
    "        # ---- Apply projection per node type ----\n",
    "        out_dict = {}\n",
    "\n",
    "        for ntype, x in x_dict.items():\n",
    "            if ntype == \"speech\":\n",
    "                out_dict[ntype] = self.speech_mlp(x.float())  # <-- IMPORTANT FIX\n",
    "            else:\n",
    "                out_dict[ntype] = self.node_lin[ntype](x.float())\n",
    "\n",
    "        # ---- HGT message passing ----\n",
    "        out_dict = self.hgt(out_dict, edge_index_dict)\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "\n",
    "class TemporalPredictor(nn.Module):\n",
    "    def __init__(self, embed_dim=64, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, seq_embeddings):\n",
    "        out, _ = self.gru(seq_embeddings)\n",
    "        return self.fc(out[:, -1])  # last timestep\n",
    "\n",
    "\n",
    "class FedSpeechModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.gnn = SpeechHeteroGNN(hidden_dim)\n",
    "        self.temporal = TemporalPredictor(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, graph_seq):\n",
    "        day_embs = []\n",
    "\n",
    "        for g in graph_seq:\n",
    "            x_dict = self.gnn(g.x_dict, g.edge_index_dict)\n",
    "            z = x_dict[\"day\"]  # shape [1, hidden_dim]\n",
    "            day_embs.append(z)\n",
    "\n",
    "        day_embs = torch.stack(day_embs, dim=1)  # [1, seq_len, hidden_dim]\n",
    "        return self.temporal(day_embs)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T17:24:25.285917Z",
     "start_time": "2025-12-10T16:59:31.672473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import analysis_utils\n",
    "\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "model = FedSpeechModel(hidden_dim=64)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "torch.serialization.add_safe_globals([HeteroData])\n",
    "\n",
    "def load_graphs(graph_dir):\n",
    "    graph_dir = Path(graph_dir)\n",
    "    graphs = []\n",
    "    for f in sorted(graph_dir.glob(\"graph_*.pt\")):\n",
    "        g = torch.load(f, weights_only=False)  # full load\n",
    "        graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "graphs = load_graphs(\"graphs_ffr_delta\") \n",
    "L = 30  # sequence length\n",
    "EPOCHS = 40  # number of epochs\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for t in range(L, len(graphs)):\n",
    "        seq = graphs[t - L:t]\n",
    "        target = graphs[t].y.float()\n",
    "\n",
    "        pred = model(seq)\n",
    "        loss = loss_fn(pred.squeeze(), target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}  MSE={total_loss / count:.6f}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingshu/Projects/kaggle/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40  MSE=0.005178\n",
      "Epoch 2/40  MSE=0.003572\n",
      "Epoch 3/40  MSE=0.003483\n",
      "Epoch 4/40  MSE=0.003532\n",
      "Epoch 5/40  MSE=0.003548\n",
      "Epoch 6/40  MSE=0.003547\n",
      "Epoch 7/40  MSE=0.003507\n",
      "Epoch 8/40  MSE=0.003522\n",
      "Epoch 9/40  MSE=0.003526\n",
      "Epoch 10/40  MSE=0.003525\n",
      "Epoch 11/40  MSE=0.003518\n",
      "Epoch 12/40  MSE=0.003573\n",
      "Epoch 13/40  MSE=0.003585\n",
      "Epoch 14/40  MSE=0.003539\n",
      "Epoch 15/40  MSE=0.003519\n",
      "Epoch 16/40  MSE=0.003520\n",
      "Epoch 17/40  MSE=0.003512\n",
      "Epoch 18/40  MSE=0.003514\n",
      "Epoch 19/40  MSE=0.003522\n",
      "Epoch 20/40  MSE=0.003531\n",
      "Epoch 21/40  MSE=0.003510\n",
      "Epoch 22/40  MSE=0.003517\n",
      "Epoch 23/40  MSE=0.003519\n",
      "Epoch 24/40  MSE=0.003517\n",
      "Epoch 25/40  MSE=0.003504\n",
      "Epoch 26/40  MSE=0.003511\n",
      "Epoch 27/40  MSE=0.003506\n",
      "Epoch 28/40  MSE=0.003493\n",
      "Epoch 29/40  MSE=0.003509\n",
      "Epoch 30/40  MSE=0.003511\n",
      "Epoch 31/40  MSE=0.003525\n",
      "Epoch 32/40  MSE=0.003504\n",
      "Epoch 33/40  MSE=0.003511\n",
      "Epoch 34/40  MSE=0.003595\n",
      "Epoch 35/40  MSE=0.003550\n",
      "Epoch 36/40  MSE=0.003513\n",
      "Epoch 37/40  MSE=0.003716\n",
      "Epoch 38/40  MSE=0.003494\n",
      "Epoch 39/40  MSE=0.003497\n",
      "Epoch 40/40  MSE=0.003502\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
