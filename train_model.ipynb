{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T02:52:27.392458Z",
          "start_time": "2025-11-12T02:52:27.380537Z"
        },
        "id": "6ffb359a5cfdf48c"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "path = r\"C:\\Users\\MainUser\\project\\cs224w_cb_graph\\info_folder\\fed_speech_graph.pt\"\n",
        "data = torch.load(path, map_location=\"cpu\", weights_only=False)"
      ],
      "id": "6ffb359a5cfdf48c",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "jupyter": {
          "is_executing": true
        },
        "id": "ac2b65b67e53679f"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
        "\n",
        "class HeteroSpeechRegressor(nn.Module):\n",
        "    def __init__(self, metadata, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        edge_types = metadata[1]\n",
        "\n",
        "        self.conv1 = HeteroConv({et: SAGEConv((-1, -1), hidden_dim)\n",
        "                                 for et in edge_types}, aggr='sum')\n",
        "        self.conv2 = HeteroConv({et: SAGEConv((-1, -1), hidden_dim)\n",
        "                                 for et in edge_types}, aggr='sum')\n",
        "        self.head = Linear(hidden_dim, 1)\n",
        "\n",
        "    def _apply_layer(self, layer, x_dict, edge_index_dict):\n",
        "        out = layer(x_dict, edge_index_dict)\n",
        "        if isinstance(out, tuple):\n",
        "            out = out[0]\n",
        "        for nt, x in x_dict.items():\n",
        "            if nt not in out:\n",
        "                out[nt] = x\n",
        "        out = {k: F.relu(v) for k, v in out.items()}\n",
        "        return out\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        h = self._apply_layer(self.conv1, x_dict, edge_index_dict)\n",
        "        h = self._apply_layer(self.conv2, h, edge_index_dict)\n",
        "        return self.head(h['speech']).squeeze(-1)\n",
        "\n"
      ],
      "id": "ac2b65b67e53679f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T02:52:34.574369Z",
          "start_time": "2025-11-12T02:52:34.563896Z"
        },
        "id": "60ded2bd533c97f7"
      },
      "cell_type": "code",
      "source": [
        "mask_finite = torch.isfinite(data['speech'].y)\n",
        "data['speech'].y = data['speech'].y[mask_finite]\n",
        "data['speech'].x = data['speech'].x[mask_finite]\n",
        "data['speech'].date = data['speech'].date[mask_finite]"
      ],
      "id": "60ded2bd533c97f7",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T02:52:38.191408Z",
          "start_time": "2025-11-12T02:52:38.187488Z"
        },
        "id": "58304d80b2c65768",
        "outputId": "22a3a4ae-0a84-418c-e883-aa61813a364a"
      },
      "cell_type": "code",
      "source": [
        "print(\"data['speech'].num_nodes:\", data['speech'].num_nodes)\n",
        "print(\"len(speech_dates):\", len(data['speech'].date))\n",
        "print(\"len(data['speech'].y):\", len(data['speech'].y))\n"
      ],
      "id": "58304d80b2c65768",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data['speech'].num_nodes: 53\n",
            "len(speech_dates): 53\n",
            "len(data['speech'].y): 53\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T02:52:41.586842Z",
          "start_time": "2025-11-12T02:52:41.572931Z"
        },
        "id": "8854af05c7b901a6",
        "outputId": "b95ed6ae-6074-4d25-c8ff-837678329ee7"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HeteroSpeechRegressor(data.metadata(), hidden_dim=128).to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fn = nn.MSELoss()\n"
      ],
      "id": "8854af05c7b901a6",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MainUser\\AppData\\Local\\Temp\\ipykernel_105008\\4222484851.py:11: UserWarning: There exist node types ({'speaker'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
            "  self.conv1 = HeteroConv({et: SAGEConv((-1, -1), hidden_dim)\n",
            "C:\\Users\\MainUser\\AppData\\Local\\Temp\\ipykernel_105008\\4222484851.py:13: UserWarning: There exist node types ({'speaker'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
            "  self.conv2 = HeteroConv({et: SAGEConv((-1, -1), hidden_dim)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T02:52:44.447124Z",
          "start_time": "2025-11-12T02:52:44.442624Z"
        },
        "id": "6a863f5d61caf051"
      },
      "cell_type": "code",
      "source": [
        "from torch_geometric.transforms import ToUndirected\n",
        "data = ToUndirected()(data)\n",
        "for nt in data.node_types:\n",
        "    if not hasattr(data[nt], 'x'):\n",
        "        N = data[nt].num_nodes\n",
        "        data[nt].x = torch.zeros((N, 1), dtype=torch.float)\n",
        "    if not hasattr(data[nt], 'num_nodes') or data[nt].num_nodes is None:\n",
        "        data[nt].num_nodes = data[nt].x.size(0)\n"
      ],
      "id": "6a863f5d61caf051",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T02:52:48.359056Z",
          "start_time": "2025-11-12T02:52:48.353107Z"
        },
        "id": "2d6a8dc6b9f6960"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "N = data['speech'].num_nodes\n",
        "idx_sorted = np.argsort(data[\"speech\"].date)\n",
        "\n",
        "train_end = int(0.7 * N)\n",
        "val_end   = int(0.85 * N)\n",
        "\n",
        "train_idx = torch.tensor(idx_sorted[:train_end], dtype=torch.long)\n",
        "val_idx   = torch.tensor(idx_sorted[train_end:val_end], dtype=torch.long)\n",
        "test_idx  = torch.tensor(idx_sorted[val_end:], dtype=torch.long)\n",
        "\n",
        "train_mask = torch.zeros(N, dtype=torch.bool)\n",
        "val_mask   = torch.zeros(N, dtype=torch.bool)\n",
        "test_mask  = torch.zeros(N, dtype=torch.bool)\n",
        "\n",
        "train_mask[train_idx] = True\n",
        "val_mask[val_idx]     = True\n",
        "test_mask[test_idx]   = True\n",
        "\n",
        "data['speech'].train_mask = train_mask\n",
        "data['speech'].val_mask   = val_mask\n",
        "data['speech'].test_mask  = test_mask\n"
      ],
      "id": "2d6a8dc6b9f6960",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T02:52:56.112866Z",
          "start_time": "2025-11-12T02:52:55.652311Z"
        },
        "id": "1b46cd72bdd3287d",
        "outputId": "0da3563b-37a5-45d9-c5ae-02f19b7abac5"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = model(data.x_dict, data.edge_index_dict)\n",
        "    loss = loss_fn(pred[data['speech'].train_mask], data['speech'].y[data['speech'].train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_pred = model(data.x_dict, data.edge_index_dict)\n",
        "            val_loss = loss_fn(val_pred[data['speech'].val_mask], data['speech'].y[data['speech'].val_mask]).item()\n",
        "\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss {loss.item():.4f} | Val Loss {val_loss:.4f}\")\n"
      ],
      "id": "1b46cd72bdd3287d",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000 | Train Loss 0.0084 | Val Loss 0.0098\n",
            "Epoch 020 | Train Loss 0.0004 | Val Loss 0.0027\n",
            "Epoch 040 | Train Loss 0.0000 | Val Loss 0.0030\n",
            "Epoch 060 | Train Loss 0.0000 | Val Loss 0.0030\n",
            "Epoch 080 | Train Loss 0.0000 | Val Loss 0.0031\n",
            "Epoch 100 | Train Loss 0.0000 | Val Loss 0.0031\n",
            "Epoch 120 | Train Loss 0.0000 | Val Loss 0.0029\n",
            "Epoch 140 | Train Loss 0.0000 | Val Loss 0.0032\n",
            "Epoch 160 | Train Loss 0.0000 | Val Loss 0.0030\n",
            "Epoch 180 | Train Loss 0.0000 | Val Loss 0.0031\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-12T02:52:59.697332Z",
          "start_time": "2025-11-12T02:52:59.692485Z"
        },
        "id": "4075eb8f78d167f8",
        "outputId": "d6fda066-06ab-4132-bba8-55420a314da0"
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred = model(data.x_dict, data.edge_index_dict)\n",
        "    test_loss = loss_fn(pred[data['speech'].test_mask], data['speech'].y[data['speech'].test_mask]).item()\n",
        "print(f\"Test MSE: {test_loss:.6f}\")\n"
      ],
      "id": "4075eb8f78d167f8",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE: 0.002906\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear, ModuleDict, ModuleList, Sequential, ReLU, LSTM\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "class hetero_attn(torch.nn.Module):\n",
        "  #uses GATv2Conv for each of the layers before prediction heads\n",
        "  def __init__ (self, graph_data, hidden, heads, layers):\n",
        "    super().__init__()\n",
        "\n",
        "    #dict mapping node types to learnable linear transformations of appropriate\n",
        "    #dimension\n",
        "\n",
        "    self.by_type = ModuleDict()\n",
        "    self.by_type[\"speech\"] = Linear(graph_data[\"speech\"].x.shape[1], hidden)\n",
        "    self.by_type[\"topic\"] = Linear(graph_data[\"topic\"].x.shape[1], hidden)\n",
        "    self.by_type[\"speaker\"] = Linear(graph_data[\"speaker\"].x.shape[1], hidden)\n",
        "\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    for i in range(layers):\n",
        "      layer = HeteroConv({\n",
        "          (\"speech\", \"discusses\", \"topic\"): GATv2Conv(-1, hidden, heads=heads, edge_dim=1, add_self_loops=False),\n",
        "          (\"speech\", \"follows\", \"speech\"): GATv2Conv(-1, hidden, heads=heads, edge_dim=1, add_self_loops=False),\n",
        "          (\"speaker\", \"authored\", \"speech\"): GATv2Conv(-1, hidden, heads=heads, edge_dim=1, add_self_loops=False),\n",
        "          (\"speaker\", \"influences\", \"topic\"): GATv2Conv(-1, hidden, heads=heads, edge_dim=1, add_self_loops=False),\n",
        "\n",
        "          (\"topic\", \"rev_discusses\", \"speech\"): GATv2Conv(-1, hidden, heads=heads, edge_dim=1, add_self_loops=False),\n",
        "          (\"speech\", \"rev_follows\", \"speech\"): GATv2Conv(-1, hidden, heads=heads, edge_dim=1, add_self_loops=False),\n",
        "          (\"speech\", \"rev_authored\", \"speaker\"): GATv2Conv(-1, hidden, heads=heads, edge_dim=1, add_self_loops=False),\n",
        "          (\"topic\", \"rev_influences\", \"speaker\"): GATv2Conv(-1, hidden, heads=heads, edge_dim=1, add_self_loops=False),\n",
        "      }, aggr=\"mean\")\n",
        "\n",
        "      self.convs.append(layer)\n",
        "\n",
        "    #output layer is a matrix mapping from vector space of the \"hidden\" dimension\n",
        "    #to the number of prediction heads (used for time series later)\n",
        "    self.dim_final = hidden * heads\n",
        "\n",
        "  def forward (self, params_map, edge_idx_map, edge_attr_map=None):\n",
        "    params_map_relu = {key : value.relu() for key, value in params_map.items()}\n",
        "\n",
        "    for layer in self.convs:\n",
        "      params_map_relu = layer(params_map, edge_idx_map, edge_attr_map)\n",
        "      params_map_relu = {key : value.relu() for key, value in params_map_relu.items()}\n",
        "\n",
        "    return params_map_relu\n",
        "\n",
        "class time_series_pred (torch.nn.Module):\n",
        "  def __init__  (self, dim_in, hidden, heads, layers, length):\n",
        "    super().__init__()\n",
        "    self.gat = hetero_attn(dim_in, hidden, heads, layers)\n",
        "    dim_final = self.gat.dim_final\n",
        "\n",
        "    self.seq = LSTM(input_size=dim_final, hidden_size=dim_final, batch_first=True)\n",
        "\n",
        "    self.pred_head = Sequential(Linear(dim_final * 2, dim_final), ReLU(), Linear(dim_final, 1))\n",
        "\n",
        "  def forward (self, data, seqs, topic_idx):\n",
        "    gat_output_emb = self.gat(data.params_map, data.edge_idx_map, getattr(data, 'edge_attr_map', None))\n",
        "\n",
        "    for_speeches = gat_output_emb['speech']\n",
        "    for_topics = gat_output_emb['topic']\n",
        "\n",
        "    for_seqs = for_speeches[seqs]\n",
        "\n",
        "    out, (hidden_state, cell) = self.lstm(for_seqs)\n",
        "    relevant = hidden_state.squeeze(0)\n",
        "\n",
        "    topics = for_topics[topic_idx]\n",
        "\n",
        "    concatenated = torch.cat([relevant, topics], dim=-1)\n",
        "    return self.pred_head(concatenated).squeeze(-1)"
      ],
      "metadata": {
        "id": "6CU1fflH6jIw"
      },
      "id": "6CU1fflH6jIw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subgraph_up_to_time (data, idx):\n",
        "  graph_so_far = copy.copy(data)\n",
        "\n",
        "  graph_so_far['speech'].x = data['speech'].x[:idx]\n",
        "\n",
        "  for rel in graph_so_far.edge_types: #in class we called these \"relation types\" where an edge-type was one component of a relation-type,\n",
        "  #i am using the same convention for naming here\n",
        "    src, et, dst = rel\n",
        "    edge_idx = graph_so_far[rel].edge_index\n",
        "\n",
        "    temporal_mask = torch.ones(edge_idx.size(1), dtype=torch.bool)\n",
        "    if src == 'speech':\n",
        "      temporal_mask &= (edge_idx[0] < idx)\n",
        "    if dst == 'speech':\n",
        "      temporal_mask &= (edge_idx[1] < idx)\n",
        "\n",
        "    graph_so_far[rel].edge_index = edge_idx[:, temporal_mask]\n",
        "\n",
        "    if 'edge_attr' in graph_so_far[rel]:\n",
        "      graph_so_far[rel].edge_attr = graph_so_far[rel].edge_attr[temporal_mask]\n",
        "\n",
        "  return graph_so_far\n",
        "\n",
        "def sliding_window (speech_idx, length):\n",
        "  seqs = []\n",
        "  pred_targets = []\n",
        "\n",
        "  for i in range(length, len(speech_idx)):\n",
        "    seq = speech_idx[i-length : i]\n",
        "    pred_target = speech_idx[i]\n",
        "    seqs.append(seq)\n",
        "    pred_targets.append(pred_target)\n",
        "\n",
        "  seqs_out = torch.stack(seqs)\n",
        "  pred_targets_out = torch.stack(pred_targets)\n",
        "\n",
        "  return seqs_out, pred_targets_out"
      ],
      "metadata": {
        "id": "0by7AYynJF6S"
      },
      "id": "0by7AYynJF6S",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}